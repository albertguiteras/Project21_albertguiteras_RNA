{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import matplotlib.pyplot as plt\n",
                "from PIL import Image"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "raw_dir = \"../data/processed/train\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# def load_images(directory, label='dog', n=9):\n",
                "#     images = []\n",
                "#     count = 0\n",
                "#     for img_name in os.listdir(directory):\n",
                "#         if label in img_name and count < n:  # Filtra solo las imágenes que contienen 'dog' en el nombre\n",
                "#             img_path = os.path.join(directory, img_name)\n",
                "#             if os.path.isfile(img_path):\n",
                "#                 # Abrir la imagen sin redimensionarla\n",
                "#                 img = Image.open(img_path)\n",
                "#                 images.append(img)\n",
                "#                 count += 1\n",
                "#     return images\n",
                "\n",
                "# # Cargar las primeras 9 imágenes de perros\n",
                "# dog_images = load_images(raw_dir, label='dog', n=9)\n",
                "\n",
                "# # Crear una figura con una fila de 9 subgráficas\n",
                "# fig, axes = plt.subplots(1, 9, figsize=(15, 5))\n",
                "\n",
                "# # Mostrar las imágenes de perros en su tamaño original\n",
                "# for i, ax in enumerate(axes):\n",
                "#     ax.imshow(dog_images[i])\n",
                "#     ax.axis('off')  # Desactivar los ejes\n",
                "\n",
                "# # Ajustar el layout para evitar solapamientos\n",
                "# plt.tight_layout()\n",
                "# plt.show()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "# def load_images(directory, label='cat', n=9):\n",
                "#     images = []\n",
                "#     count = 0\n",
                "#     for img_name in os.listdir(directory):\n",
                "#         if label in img_name and count < n:  # Filtra solo las imágenes que contienen 'cat' en el nombre\n",
                "#             img_path = os.path.join(directory, img_name)\n",
                "#             if os.path.isfile(img_path):\n",
                "#                 # Abrir la imagen sin redimensionarla\n",
                "#                 img = Image.open(img_path)\n",
                "#                 images.append(img)\n",
                "#                 count += 1\n",
                "#     return images\n",
                "\n",
                "# # Cargar las primeras 9 imágenes de gatos\n",
                "# cat_images = load_images(raw_dir, label='cat', n=9)\n",
                "\n",
                "# # Crear una figura con una fila de 9 subgráficas\n",
                "# fig, axes = plt.subplots(1, 9, figsize=(15, 5))\n",
                "\n",
                "# # Mostrar las imágenes de gatos en su tamaño original\n",
                "# for i, ax in enumerate(axes):\n",
                "#     ax.imshow(cat_images[i])\n",
                "#     ax.axis('off')  # Desactivar los ejes\n",
                "\n",
                "# # Ajustar el layout para evitar solapamientos\n",
                "# plt.tight_layout()\n",
                "# plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Las imágenes se han movido correctamente a las carpetas correspondientes.\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import shutil\n",
                "\n",
                "# Definir el directorio de entrada y salida\n",
                "train_dir = '../data/raw/train0'  # Carpeta donde están las imágenes sin organizar\n",
                "pro_dir = '../data/processed/train'\n",
                "\n",
                "dog_dir = os.path.join(pro_dir, 'dog')  # Carpeta donde se guardarán las imágenes de perros\n",
                "cat_dir = os.path.join(pro_dir, 'cat')  # Carpeta donde se guardarán las imágenes de gatos\n",
                "\n",
                "# Crear las carpetas para perros y gatos si no existen\n",
                "os.makedirs(dog_dir, exist_ok=True)\n",
                "os.makedirs(cat_dir, exist_ok=True)\n",
                "\n",
                "# Iterar sobre todas las imágenes en el directorio de entrada\n",
                "for img_name in os.listdir(train_dir):\n",
                "    img_path = os.path.join(train_dir, img_name)\n",
                "    \n",
                "    # Verificar que es un archivo y no una carpeta\n",
                "    if os.path.isfile(img_path):\n",
                "        if 'dog' in img_name.lower():  # Si el nombre del archivo contiene 'dog'\n",
                "            shutil.move(img_path, os.path.join(dog_dir, img_name))  # Mover a la carpeta 'dog'\n",
                "        elif 'cat' in img_name.lower():  # Si el nombre del archivo contiene 'cat'\n",
                "            shutil.move(img_path, os.path.join(cat_dir, img_name))  # Mover a la carpeta 'cat'\n",
                "\n",
                "print(\"Las imágenes se han movido correctamente a las carpetas correspondientes.\") "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Found 25000 images belonging to 2 classes.\n",
                        "Found 12500 images belonging to 1 classes.\n"
                    ]
                }
            ],
            "source": [
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "\n",
                "# Define a few rules for DataGen\n",
                "train_dir = \"../data/processed/train\"\n",
                "test_dir = \"../data/raw\"\n",
                "\n",
                "datagentrain = ImageDataGenerator()\n",
                "datagentest = ImageDataGenerator()\n",
                "\n",
                "# Train Data Generation\n",
                "train_data = datagentrain.flow_from_directory(\n",
                "    train_dir,\n",
                "    classes=[\"dog\", \"cat\"],  # Especificamos las clases\n",
                "    target_size=(200, 200),   # Redimensionar todas las imágenes a 200x200 píxeles\n",
                "    batch_size=32,            # Tamaño del lote\n",
                "    class_mode='categorical'  # Tipo de etiquetas (categorical)\n",
                ")\n",
                "\n",
                "# Test Data Generation\n",
                "test_data = datagentest.flow_from_directory(\n",
                "    test_dir,\n",
                "    classes=[\"test0\"],         # Puedes cambiar \"test\" por las clases de test si es necesario\n",
                "    target_size=(200, 200),   # Redimensionar todas las imágenes a 200x200 píxeles\n",
                "    batch_size=32,            # Tamaño del lote\n",
                "    class_mode='categorical'  # Tipo de etiquetas (categorical)\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Move the Data Through the Neural Network\n",
                "from keras.models import Sequential\n",
                "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
                "\n",
                "model = Sequential()\n",
                "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 64,kernel_size = (3,3),padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "\n",
                "# Move the Data through the Dense Layers\n",
                "model.add(Flatten())\n",
                "model.add(Dense(units = 4096,activation = \"relu\"))\n",
                "model.add(Dense(units = 4096,activation = \"relu\"))\n",
                "model.add(Dense(units = 2, activation = \"softmax\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-04-08 22:48:30.025514: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
                    ]
                },
                {
                    "ename": "",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31mEl kernel se bloqueó al ejecutar código en la celda actual o en una celda anterior. \n",
                        "\u001b[1;31mRevise el código de las celdas para identificar una posible causa del error. \n",
                        "\u001b[1;31mHaga clic <a href='https://aka.ms/vscodeJupyterKernelCrash'>aquí</a> para obtener más información. \n",
                        "\u001b[1;31mVea Jupyter <a href='command:jupyter.viewOutput'>log</a> para obtener más detalles."
                    ]
                }
            ],
            "source": [
                "# Compile the Model using Adam \n",
                "from tensorflow.keras.optimizers import Adam\n",
                "from tensorflow.keras.losses import categorical_crossentropy\n",
                "\n",
                "# Compilar el modelo\n",
                "model.compile(\n",
                "    loss=categorical_crossentropy,  # Uso correcto de categorical_crossentropy\n",
                "    optimizer=Adam(learning_rate=0.001),\n",
                "    metrics=[\"accuracy\"]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/vscode/.local/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
                        "  self._warn_if_super_not_called()\n"
                    ]
                }
            ],
            "source": [
                "# Train the Model\n",
                "model.fit(train_data, epochs = 1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-04-08 22:48:20.634876: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
                        "2025-04-08 22:48:20.636214: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
                        "2025-04-08 22:48:20.639826: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
                        "2025-04-08 22:48:20.648728: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
                        "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
                        "E0000 00:00:1744152500.664253   14734 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
                        "E0000 00:00:1744152500.668621   14734 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
                        "W0000 00:00:1744152500.681189   14734 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1744152500.681212   14734 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1744152500.681214   14734 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1744152500.681215   14734 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "2025-04-08 22:48:20.685125: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
                        "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
                    ]
                },
                {
                    "ename": "NameError",
                    "evalue": "name 'model' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m checkpoint = ModelCheckpoint(\u001b[33m\"\u001b[39m\u001b[33m../models/vgg16_1.h5\u001b[39m\u001b[33m\"\u001b[39m, monitor = \u001b[33m\"\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m\"\u001b[39m, verbose = \u001b[32m1\u001b[39m, save_best_only = \u001b[38;5;28;01mTrue\u001b[39;00m, save_weights_only = \u001b[38;5;28;01mFalse\u001b[39;00m, mode = \u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m early = EarlyStopping(monitor = \u001b[33m\"\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m\"\u001b[39m, patience = \u001b[32m3\u001b[39m, verbose = \u001b[32m1\u001b[39m, mode = \u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m hist = \u001b[43mmodel\u001b[49m.fit(train_data, steps_per_epoch = \u001b[32m100\u001b[39m, validation_data = test_data, validation_steps = \u001b[32m10\u001b[39m, epochs = \u001b[32m3\u001b[39m, callbacks = [checkpoint, early])\n",
                        "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
                    ]
                }
            ],
            "source": [
                "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
                "\n",
                "checkpoint = ModelCheckpoint(\"../models/vgg16_1.h5\", monitor = \"val_accuracy\", verbose = 1, save_best_only = True, save_weights_only = False, mode = \"auto\")\n",
                "early = EarlyStopping(monitor = \"val_accuracy\", patience = 3, verbose = 1, mode = \"auto\")\n",
                "hist = model.fit(train_data, steps_per_epoch = 100, validation_data = test_data, validation_steps = 10, epochs = 3, callbacks = [checkpoint, early])"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
